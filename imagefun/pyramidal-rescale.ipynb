{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "os.environ[\"THEANO_FLAGS\"] = \"device=gpu\"\n",
    "sys.path.append(os.getcwd()+\"/..\")\n",
    "from tasks import check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data import load_data\n",
    "from lasagnekit.datasets.rescaled import Rescaled\n",
    "from lasagnekit.easy import iterate_minibatches\n",
    "from lasagnekit.datasets.imagecollection import ImageCollection\n",
    "from lasagnekit.datasets.transformed import Transformed\n",
    "from lasagnekit.datasets.stl import STL\n",
    "from lasagnekit.datasets.helpers import load_once, split\n",
    "from lasagnekit.datasets.subsampled import SubSampled\n",
    "from lasagnekit.datasets.imagecollection import ImageCollection\n",
    "\n",
    "w, h = 32, 32\n",
    "\n",
    "folder = \"{}/icons\".format(os.getenv(\"DATA_PATH\"))\n",
    "data_scale1 = ImageCollection(size=(w, h), nb=1600, folder=folder, mode='all')\n",
    "#data_scale1 = load_once(STL)(kind='unlabeled')\n",
    "data_scale1.load()\n",
    "del data_scale1.y\n",
    "\n",
    "up = 2\n",
    "scale = {1: w, 2: w/up}\n",
    "batch_size = 128\n",
    "\n",
    "c = 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_scale1.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_training_data = len(data_scale1.X)\n",
    "valid_ratio = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_scale1.X = data_scale1.X[0:nb_training_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_scale1_train, data_scale1_test = split(data_scale1, test_size=valid_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_scale1_train = SubSampled(data_scale1, batch_size, mode='batch')\n",
    "data_scale2_train = Rescaled(data_scale1_train, (scale[2], scale[2]))\n",
    "data_scale2_train_up = Rescaled(data_scale2_train, (scale[1], scale[1]))\n",
    "\n",
    "input_output_same_size = False\n",
    "if input_output_same_size is True:\n",
    "    data_scale2_train = data_scale2_train_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_scale2_test = Rescaled(data_scale1_test, (scale[2], scale[2]))\n",
    "data_scale2_test_up = Rescaled(data_scale2_test, (scale[1], scale[1]))\n",
    "if input_output_same_size is True:\n",
    "    data_scale2_test = data_scale2_test_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_scale2_test.load()\n",
    "data_scale2_test_up.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(x, s=32):\n",
    "    x = x.reshape((x.shape[0], s, s, c))\n",
    "    x = x.transpose((0, 3, 1, 2))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from model import model58, model60, model62, model63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter_size = [2] + [5] * 4\n",
    "all_layers = model63(nb_filters=128, filter_size=filter_size, w=None, h=None, c=c, up=up, nb_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano.tensor as T\n",
    "import theano\n",
    "from lasagne import layers\n",
    "\n",
    "X = T.tensor4()\n",
    "Y = T.tensor4()\n",
    "\n",
    "Y_pred = (layers.get_output(all_layers['output'], X))\n",
    "loss = ((Y_pred - Y) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne import updates\n",
    "import numpy as np\n",
    "params = layers.get_all_params(all_layers.values(), trainable=True)\n",
    "print(\"Number of params : {}\".format(layers.count_params(all_layers.values(), trainable=True))) \n",
    "lr = theano.shared(np.array(0.1, dtype=theano.config.floatX))\n",
    "params_updates = updates.adam(loss, params, learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagnekit.misc.draw_net import draw_to_file\n",
    "from IPython.display import SVG\n",
    "draw_to_file(layers.get_all_layers(all_layers['output']), 'out.svg')\n",
    "SVG('out.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_fn = theano.function([X, Y], loss, updates=params_updates, on_unused_input='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_fn = theano.function([X], Y_pred, on_unused_input='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time, sleep\n",
    "a = 0.001\n",
    "lr.set_value(a)\n",
    "train_loss = []\n",
    "test_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_epochs = 100\n",
    "nb_updates_per_epoch = nb_training_data / batch_size\n",
    "if nb_training_data % batch_size > 0:\n",
    "    nb_updates_per_epoch += 1\n",
    "nb_updates = nb_epochs * nb_updates_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "for epoch in range(nb_epochs):\n",
    "    train_loss_cur = []\n",
    "    for i in range(nb_updates_per_epoch):\n",
    "        data_scale1_train.load()\n",
    "        data_scale2_train.load()\n",
    "        if input_output_same_size == False:\n",
    "            data_scale2_train_up.load()\n",
    "        # update parameters based on one minibatch\n",
    "        X_scale1 = preprocess(data_scale1_train.X, s=scale[1])\n",
    "        if input_output_same_size:\n",
    "            X_scale2 = preprocess(data_scale2_train.X, s=scale[1])\n",
    "        else:\n",
    "            X_scale2 = preprocess(data_scale2_train.X, s=scale[2])\n",
    "        X_scale2_up = preprocess(data_scale2_train_up.X, s=scale[1])\n",
    "        loss_val = train_fn(X_scale2, X_scale1 - X_scale2_up)\n",
    "        train_loss_cur.append(loss_val)\n",
    "    total_loss = np.mean(train_loss_cur)\n",
    "    print('Train loss : {}'.format(total_loss))\n",
    "    train_loss.append(total_loss)\n",
    "    #if epoch % 5 == 0 and i > 0:\n",
    "    #    a = a / 2.\n",
    "    #    lr.set_value(a)\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        delta = time() - start\n",
    "        start = time()\n",
    "        print('Nb of seconds to the last validation step : {}'.format(delta))\n",
    "        print(\"computing test performance\")\n",
    "        X_scale1 = preprocess(data_scale1_test.X, s=scale[1])\n",
    "        if input_output_same_size:\n",
    "            X_scale2 = preprocess(data_scale2_test.X, s=scale[1])\n",
    "        else:\n",
    "            X_scale2 = preprocess(data_scale2_test.X, s=scale[2])\n",
    "        X_scale2_up = preprocess(data_scale2_test_up.X, s=scale[1])\n",
    "        # test the model on test data\n",
    "        total_loss = 0.\n",
    "        nb = 0\n",
    "        for mini_batch in iterate_minibatches(len(X_scale1), batch_size):\n",
    "            resid = (X_scale1[mini_batch] - X_scale2_up[mini_batch])\n",
    "            pred_resid = predict_fn(X_scale2[mini_batch])\n",
    "            loss_val = ((pred_resid - resid) ** 2).mean()\n",
    "            total_loss += loss_val\n",
    "            nb += 1\n",
    "        total_loss /= nb\n",
    "        test_loss.append(total_loss)\n",
    "        print('train_loss : {}, test_loss : {}'.format(train_loss[-1], test_loss[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(test_loss, label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out1 = X_scale2[0:100]\n",
    "for i in range(1):\n",
    "    out1 = predict_fn(out1)\n",
    "#out1 = X_scale1[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from lasagnekit.misc.plot_weights import dispims_color\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "#fig = plt.figure()\n",
    "img = dispims_color(X_scale2[0:100].transpose((0, 2, 3, 1)),border=1)\n",
    "plt.imshow(img, interpolation='none')\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "#fig = plt.figure()\n",
    "\n",
    "img = dispims_color((out1[0:100] + X_scale2_up[0:100]).transpose((0, 2, 3, 1)),border=1)\n",
    "plt.imshow(img, interpolation='none')\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "#fig = plt.figure()\n",
    "\n",
    "img = dispims_color(X_scale1[0:100].transpose((0, 2, 3, 1)),border=1)\n",
    "plt.imshow(img, interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from lasagnekit.misc.plot_weights import dispims_color\n",
    "\n",
    "ss = np.random.uniform(size=(10, c, 32, 32)) \n",
    "ss = ss.astype(np.float32)\n",
    "for i in range(1):\n",
    "    ss = predict_fn(ss)\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "img = dispims_color(ss[0:100].transpose((0, 2, 3, 1)),border=1)\n",
    "plt.axis('off')\n",
    "plt.imshow(img, interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outl = all_layers['output']\n",
    "L = layers.get_all_layers(outl)\n",
    "conv = L[1]\n",
    "w = conv.W.get_value()\n",
    "w = w.transpose((0, 1, 2, 3))\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "img = dispims_color(w.transpose((0, 2, 3, 1)), border=1)\n",
    "plt.imshow(img, interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import rescale\n",
    "\n",
    "D = imread('icon.png')\n",
    "D = D[:, :, 0:3]\n",
    "orig_D = D.copy()\n",
    "\n",
    "D_rescaled = rescale(D, (1./2, 1./2), preserve_range=True) \n",
    "D_up = rescale(D_rescaled, (2, 2), preserve_range=True)\n",
    "\n",
    "D_rescaled /= 255.\n",
    "D_up /= 255.\n",
    "\n",
    "D_rescaled = D_rescaled[None, :, :, :].transpose((0, 3, 1, 2))\n",
    "D_up = D_up[None, :, :, :].transpose((0, 3, 1, 2))\n",
    "\n",
    "D_rescaled = D_rescaled.astype(np.float32)\n",
    "D_up = D_up.astype(np.float32)\n",
    "\n",
    "\n",
    "Dhat = predict_fn(D_rescaled) + D_up\n",
    "\n",
    "Dhat = Dhat.transpose((0, 2, 3, 1))\n",
    "Dhat = Dhat[0]\n",
    "Dhat = (Dhat - Dhat.min()) / (Dhat.max() - Dhat.min())\n",
    "plt.imshow(D_rescaled.transpose((0, 2, 3, 1))[0], interpolation='none')\n",
    "plt.show()\n",
    "plt.imshow(Dhat, interpolation='none')\n",
    "plt.show()\n",
    "plt.imshow(orig_D, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
